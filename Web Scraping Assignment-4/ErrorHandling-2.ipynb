{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dc2be18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\hp\\anaconda3\\lib\\site-packages (4.9.1)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from selenium) (2022.12.7)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from selenium) (1.26.14)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from selenium) (0.10.2)\n",
      "Requirement already satisfied: outcome in c:\\users\\hp\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\hp\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: idna in c:\\users\\hp\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.1.1)\n",
      "Requirement already satisfied: sniffio in c:\\users\\hp\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\hp\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f922c3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "from selenium.common.exceptions import NoSuchElementException, TimeoutException\n",
    "\n",
    "import urllib.request\n",
    "\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "import requests\n",
    "import re\n",
    "\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8cd62f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(r\"chromedriver.exe\")\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33f7e21",
   "metadata": {},
   "source": [
    "Scrape the details of most viewed videos on YouTube from Wikipedia.\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\n",
    "You need to find following details:\n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e324833",
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_url=driver.get(\"https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc3aa8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank=[]\n",
    "name=[]\n",
    "artist=[]\n",
    "date=[]\n",
    "views=[]\n",
    "\n",
    "# scraping Rank of the videos\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH, \"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[1]\"):\n",
    "        if(i.text)!='':\n",
    "            rank.append(i.text)\n",
    "        else:\n",
    "            rank.append(\"--\")\n",
    "except NoSuchElementException:\n",
    "    rank.append(\"--\")\n",
    "    \n",
    "# Scraping Name of the videos\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH, \"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[2]\"):\n",
    "        if(i.text)!='':\n",
    "            name.append(i.text[:-4])\n",
    "        else:\n",
    "            name.append(\"--\")\n",
    "except NoSuchElementException:\n",
    "    name.append(\"--\")\n",
    "    \n",
    "# Scraping Artist of the videos\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH, \"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[3]\"):\n",
    "        if.text!='':\n",
    "            artist.append(i.text)\n",
    "        else:\n",
    "            artist.append(\"--\")\n",
    "except NoSuchElementException:\n",
    "    artist.append(\"--\")\n",
    "        \n",
    "# Scraping Upload_Date of the videos\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH, \"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[5]\"):\n",
    "        if(i.text)!='':\n",
    "            date.append(i.text)\n",
    "        else:\n",
    "            date.append(\"--\")\n",
    "except NoSuchElementException:\n",
    "    date.append(\"--\")\n",
    "        \n",
    "# Scraping Views of the videos\n",
    "try:\n",
    "    for i in driver.find_elements(By.XPATH, \"//table[@class='wikitable sortable jquery-tablesorter'][1]/tbody/tr/td[4]\"):\n",
    "        if(i.text)!='':\n",
    "            views.append(i.text)\n",
    "        else:\n",
    "            views.append(\"--\")\n",
    "except NoSuchElementException:\n",
    "    views.append(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e51686ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Video Name</th>\n",
       "      <th>Uploader</th>\n",
       "      <th>Views</th>\n",
       "      <th>Published Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>12.85</td>\n",
       "      <td>June 17, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>8.16</td>\n",
       "      <td>January 12, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>6.70</td>\n",
       "      <td>October 8, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Bath Song\"</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>6.20</td>\n",
       "      <td>May 2, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"Shape of You\"</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>6.00</td>\n",
       "      <td>January 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"See You Again\"</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>5.89</td>\n",
       "      <td>April 6, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Phonics Song with Two Words\"</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>5.30</td>\n",
       "      <td>March 6, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Wheels on the Bus\"</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>5.24</td>\n",
       "      <td>May 24, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Uptown Funk\"</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>4.92</td>\n",
       "      <td>November 19, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>4.89</td>\n",
       "      <td>February 27, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Gangnam Style\"</td>\n",
       "      <td>Psy</td>\n",
       "      <td>4.80</td>\n",
       "      <td>July 15, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>4.55</td>\n",
       "      <td>January 31, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>4.35</td>\n",
       "      <td>April 5, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Axel F\"</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>3.91</td>\n",
       "      <td>June 16, 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Sugar\"</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.87</td>\n",
       "      <td>January 14, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Roar\"</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.80</td>\n",
       "      <td>September 5, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Counting Stars\"</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>3.79</td>\n",
       "      <td>May 31, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Sorry\"</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>3.66</td>\n",
       "      <td>October 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>3.64</td>\n",
       "      <td>June 25, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Thinking Out Loud\"</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.60</td>\n",
       "      <td>October 7, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>3.59</td>\n",
       "      <td>June 4, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Dark Horse\"</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.52</td>\n",
       "      <td>February 20, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Lakdi Ki Kathi\"</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>3.48</td>\n",
       "      <td>June 14, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Faded\"</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>3.45</td>\n",
       "      <td>December 3, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Perfect\"</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.45</td>\n",
       "      <td>November 9, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Let Her Go\"</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>3.44</td>\n",
       "      <td>July 25, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Girls Like You\"</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.42</td>\n",
       "      <td>May 31, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"</td>\n",
       "      <td>Kiddiestv Hindi – Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>3.41</td>\n",
       "      <td>January 26, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Lean On\"</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>3.38</td>\n",
       "      <td>March 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Bailando\"</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>3.38</td>\n",
       "      <td>April 11, 2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                   Video Name  \\\n",
       "0    1.                            \"Baby Shark Dance   \n",
       "1    2.                                   \"Despacito   \n",
       "2    3.                       \"Johny Johny Yes Papa\"   \n",
       "3    4.                                  \"Bath Song\"   \n",
       "4    5.                               \"Shape of You\"   \n",
       "5    6.                              \"See You Again\"   \n",
       "6    7.                \"Phonics Song with Two Words\"   \n",
       "7    8.                          \"Wheels on the Bus\"   \n",
       "8    9.                                \"Uptown Funk\"   \n",
       "9   10.  \"Learning Colors – Colorful Eggs on a Farm\"   \n",
       "10  11.                              \"Gangnam Style\"   \n",
       "11  12.   \"Masha and the Bear – Recipe for Disaster\"   \n",
       "12  13.                             \"Dame Tu Cosita\"   \n",
       "13  14.                                     \"Axel F\"   \n",
       "14  15.                                      \"Sugar\"   \n",
       "15  16.                                       \"Roar\"   \n",
       "16  17.                             \"Counting Stars\"   \n",
       "17  18.                                      \"Sorry\"   \n",
       "18  19.                        \"Baa Baa Black Sheep\"   \n",
       "19  20.                          \"Thinking Out Loud\"   \n",
       "20  21.           \"Waka Waka (This Time for Africa)\"   \n",
       "21  22.                                 \"Dark Horse\"   \n",
       "22  23.                             \"Lakdi Ki Kathi\"   \n",
       "23  24.                                      \"Faded\"   \n",
       "24  25.                                    \"Perfect\"   \n",
       "25  26.                                 \"Let Her Go\"   \n",
       "26  27.                             \"Girls Like You\"   \n",
       "27  28.          \"Humpty the train on a fruits ride\"   \n",
       "28  29.                                    \"Lean On\"   \n",
       "29  30.                                   \"Bailando\"   \n",
       "\n",
       "                                         Uploader  Views     Published Date  \n",
       "0     Pinkfong Baby Shark - Kids' Songs & Stories  12.85      June 17, 2016  \n",
       "1                                      Luis Fonsi   8.16   January 12, 2017  \n",
       "2                                     LooLoo Kids   6.70    October 8, 2016  \n",
       "3                      Cocomelon – Nursery Rhymes   6.20        May 2, 2018  \n",
       "4                                      Ed Sheeran   6.00   January 30, 2017  \n",
       "5                                     Wiz Khalifa   5.89      April 6, 2015  \n",
       "6                                       ChuChu TV   5.30      March 6, 2014  \n",
       "7                      Cocomelon – Nursery Rhymes   5.24       May 24, 2018  \n",
       "8                                     Mark Ronson   4.92  November 19, 2014  \n",
       "9                                     Miroshka TV   4.89  February 27, 2018  \n",
       "10                                            Psy   4.80      July 15, 2012  \n",
       "11                                     Get Movies   4.55   January 31, 2012  \n",
       "12                                      El Chombo   4.35      April 5, 2018  \n",
       "13                                     Crazy Frog   3.91      June 16, 2009  \n",
       "14                                       Maroon 5   3.87   January 14, 2015  \n",
       "15                                     Katy Perry   3.80  September 5, 2013  \n",
       "16                                    OneRepublic   3.79       May 31, 2013  \n",
       "17                                  Justin Bieber   3.66   October 22, 2015  \n",
       "18                     Cocomelon – Nursery Rhymes   3.64      June 25, 2018  \n",
       "19                                     Ed Sheeran   3.60    October 7, 2014  \n",
       "20                                        Shakira   3.59       June 4, 2010  \n",
       "21                                     Katy Perry   3.52  February 20, 2014  \n",
       "22                                   Jingle Toons   3.48      June 14, 2018  \n",
       "23                                    Alan Walker   3.45   December 3, 2015  \n",
       "24                                     Ed Sheeran   3.45   November 9, 2017  \n",
       "25                                      Passenger   3.44      July 25, 2012  \n",
       "26                                       Maroon 5   3.42       May 31, 2018  \n",
       "27  Kiddiestv Hindi – Nursery Rhymes & Kids Songs   3.41   January 26, 2018  \n",
       "28                                    Major Lazer   3.38     March 22, 2015  \n",
       "29                               Enrique Iglesias   3.38     April 11, 2014  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data={'Rank':rank, 'Video Name':name, 'Uploader':artist, 'Views':views, 'Published Date':date}\n",
    "df = pd.DataFrame.from_dict(data, orient='index')\n",
    "df = df.transpose()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4c5f07",
   "metadata": {},
   "source": [
    "Scrape the details teamIndia’sinternationalfixtures from bcci.tv. \n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Match title (I.e. 1stODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02b1b05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bssi_url=driver.get(\"https://www.bcci.tv/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bf7371f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    wait=WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.CLASS_NAME, \"cookie\")))\n",
    "    x=wait.find_element(By.CLASS_NAME,\"cookie__accept\")\n",
    "    x.click()\n",
    "except TimeoutException as e:\n",
    "    print(e) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4169fbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    nav_btn=driver.find_element(By.XPATH, '//*[@id=\"navigation\"]/ul[1]/li[2]')\n",
    "    nav_btn.click()\n",
    "except NoSuchElementException:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fc66a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# click on more fixtures\n",
    "try:\n",
    "    time.sleep(3)\n",
    "    fixtures= driver.find_element(By.XPATH, '//*[@id=\"fixtures\"]/div[3]/div[2]/div/button')\n",
    "    fixtures.click()\n",
    "    time.sleep(3)\n",
    "except NoSuchElementException:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b626f650",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Empty list\n",
    "match_title=[]\n",
    "match_series=[]\n",
    "match_place=[]\n",
    "match_date=[]\n",
    "match_time=[]\n",
    "\n",
    "#Scraping Match_title\n",
    "try:\n",
    "    title= driver.find_elements(By.XPATH, '//*[@id=\"match-card\"]/div[3]/div/span[1]')\n",
    "    for i in title:\n",
    "        if(i.text)!='':\n",
    "            name=i.text[:-1].split('-')[0]\n",
    "            match_title.append(name)\n",
    "        else:\n",
    "            match_title.append('--')\n",
    "except NoSuchElementException:\n",
    "    match_title.append('--')\n",
    "    \n",
    "#Scraping Series\n",
    "try:\n",
    "    series= driver.find_elements(By.XPATH, \"//div[@class='match-card-top']/h5\")\n",
    "    for i in series:\n",
    "        if(i.text)!='':\n",
    "            match_series.append(i.text)\n",
    "        else:\n",
    "            match_series.append('--')\n",
    "except NoSuchElementException:\n",
    "    match_series.append('--')\n",
    "    \n",
    "#Scraping Place\n",
    "try:\n",
    "    places=driver.find_elements(By.XPATH, '//*[@id=\"match-card\"]/div[3]/div')\n",
    "    for i in places:\n",
    "        if(i.text)!='':\n",
    "            place=i.text.split('-')[1]\n",
    "            match_place.append(place)\n",
    "        else:\n",
    "            match_place.append('--')\n",
    "except NoSuchElementException:\n",
    "    match_place.append('--')\n",
    "    \n",
    "#Scraping Date\n",
    "try:\n",
    "    dates=driver.find_elements(By.CLASS_NAME, 'match-dates')\n",
    "    for i in dates:\n",
    "        if(i.text)!='':\n",
    "            match_date.append(i.text)\n",
    "        else:\n",
    "            match_date.append('--')\n",
    "except NoSuchElementException:\n",
    "    match_date.append('--')\n",
    "\n",
    "#Scraping Time\n",
    "try:\n",
    "    timings=driver.find_elements(By.CLASS_NAME, 'match-time')\n",
    "    for i in timings:\n",
    "        if(i.text)!='':\n",
    "            match_time.append(i.text)\n",
    "        else:\n",
    "            match_time.append('--')\n",
    "except NoSuchElementException:\n",
    "    match_time.append('--')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdb53ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match Title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1st Test</td>\n",
       "      <td>INDIA TOUR OF WEST INDIES 2023</td>\n",
       "      <td>Windsor Park, Dominica</td>\n",
       "      <td>12 JUL 2023</td>\n",
       "      <td>3:00 PM BST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2nd Test</td>\n",
       "      <td>INDIA TOUR OF WEST INDIES 2023</td>\n",
       "      <td>Queen's Park Oval, Trinidad</td>\n",
       "      <td>20 JUL 2023</td>\n",
       "      <td>3:00 PM BST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1st ODI</td>\n",
       "      <td>INDIA TOUR OF WEST INDIES 2023</td>\n",
       "      <td>Kensington Oval, Barbados</td>\n",
       "      <td>27 JUL 2023</td>\n",
       "      <td>2:30 PM BST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2nd ODI</td>\n",
       "      <td>INDIA TOUR OF WEST INDIES 2023</td>\n",
       "      <td>Kensington Oval, Barbados</td>\n",
       "      <td>29 JUL 2023</td>\n",
       "      <td>2:30 PM BST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3rd ODI</td>\n",
       "      <td>INDIA TOUR OF WEST INDIES 2023</td>\n",
       "      <td>Brian Lara Stadium, Trinidad</td>\n",
       "      <td>1 AUG 2023</td>\n",
       "      <td>2:30 PM BST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1st T20I</td>\n",
       "      <td>INDIA TOUR OF WEST INDIES 2023</td>\n",
       "      <td>Brian Lara Stadium, Trinidad</td>\n",
       "      <td>3 AUG 2023</td>\n",
       "      <td>3:30 PM BST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2nd T20I</td>\n",
       "      <td>INDIA TOUR OF WEST INDIES 2023</td>\n",
       "      <td>National Stadium, Guyana</td>\n",
       "      <td>6 AUG 2023</td>\n",
       "      <td>3:30 PM BST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3rd T20I</td>\n",
       "      <td>INDIA TOUR OF WEST INDIES 2023</td>\n",
       "      <td>National Stadium, Guyana</td>\n",
       "      <td>8 AUG 2023</td>\n",
       "      <td>3:30 PM BST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4th T20I</td>\n",
       "      <td>INDIA TOUR OF WEST INDIES 2023</td>\n",
       "      <td>Central Broward Regional Park Stadium Turf Gr...</td>\n",
       "      <td>12 AUG 2023</td>\n",
       "      <td>3:30 PM BST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5th T20I</td>\n",
       "      <td>INDIA TOUR OF WEST INDIES 2023</td>\n",
       "      <td>Central Broward Regional Park Stadium Turf Gr...</td>\n",
       "      <td>13 AUG 2023</td>\n",
       "      <td>3:30 PM BST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Match Title                          Series  \\\n",
       "0   1st Test   INDIA TOUR OF WEST INDIES 2023   \n",
       "1   2nd Test   INDIA TOUR OF WEST INDIES 2023   \n",
       "2    1st ODI   INDIA TOUR OF WEST INDIES 2023   \n",
       "3    2nd ODI   INDIA TOUR OF WEST INDIES 2023   \n",
       "4    3rd ODI   INDIA TOUR OF WEST INDIES 2023   \n",
       "5   1st T20I   INDIA TOUR OF WEST INDIES 2023   \n",
       "6   2nd T20I   INDIA TOUR OF WEST INDIES 2023   \n",
       "7   3rd T20I   INDIA TOUR OF WEST INDIES 2023   \n",
       "8   4th T20I   INDIA TOUR OF WEST INDIES 2023   \n",
       "9   5th T20I   INDIA TOUR OF WEST INDIES 2023   \n",
       "\n",
       "                                               Place         Date         Time  \n",
       "0                             Windsor Park, Dominica  12 JUL 2023  3:00 PM BST  \n",
       "1                        Queen's Park Oval, Trinidad  20 JUL 2023  3:00 PM BST  \n",
       "2                          Kensington Oval, Barbados  27 JUL 2023  2:30 PM BST  \n",
       "3                          Kensington Oval, Barbados  29 JUL 2023  2:30 PM BST  \n",
       "4                       Brian Lara Stadium, Trinidad   1 AUG 2023  2:30 PM BST  \n",
       "5                       Brian Lara Stadium, Trinidad   3 AUG 2023  3:30 PM BST  \n",
       "6                           National Stadium, Guyana   6 AUG 2023  3:30 PM BST  \n",
       "7                           National Stadium, Guyana   8 AUG 2023  3:30 PM BST  \n",
       "8   Central Broward Regional Park Stadium Turf Gr...  12 AUG 2023  3:30 PM BST  \n",
       "9   Central Broward Regional Park Stadium Turf Gr...  13 AUG 2023  3:30 PM BST  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data={'Match Title':match_title, 'Series':match_series, 'Place':match_place, 'Date':match_date, 'Time':match_time}\n",
    "df = pd.DataFrame.from_dict(data, orient='index')\n",
    "df = df.transpose()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a630857",
   "metadata": {},
   "source": [
    "Scrape the details of State-wise GDP ofIndia fromstatisticstime.com. \n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details:\n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)- at current prices\n",
    "D) GSDP(19-20)- at current prices\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52cccb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_gdp=driver.get(\"https://www.statisticstimes.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6d0d5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Click Economy\n",
    "try:\n",
    "    nav_btn=driver.find_element(By.XPATH, \"//*[@id='top']/div[2]/div[2]/button\")\n",
    "    nav_btn.click()\n",
    "except NoSuchElementException as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dbf7b331",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Click India\n",
    "try:\n",
    "    nav_india= driver.find_element(By.XPATH, \"//*[@id='top']/div[2]/div[2]/div/a[3]\")\n",
    "    nav_india.click()\n",
    "except NoSuchElementException as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6012ebb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click on GDP of Indian States\n",
    "try:\n",
    "    nav_link=driver.find_element(By.XPATH, '/html/body/div[2]/div[2]/div[2]/ul/li[1]/a')\n",
    "    nav_link.click()\n",
    "except NoSuchElementException as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e941f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    wait=WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.CLASS_NAME, 'qc-cmp2-summary-section')))\n",
    "    x=wait.find_element(By.XPATH, '//*[@id=\"qc-cmp2-ui\"]/div[2]/div/button[2]')\n",
    "    x.click()\n",
    "    time.sleep(5)\n",
    "except TimeoutException as e:\n",
    "    print(e) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43d6d727",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank=[]\n",
    "state=[]\n",
    "gsdp1=[]\n",
    "gsdp2=[]\n",
    "share=[]\n",
    "gdp=[]\n",
    "\n",
    "#Scraping Range\n",
    "try:\n",
    "    ranks= driver.find_elements(By.XPATH, \"//div[@id='table_id_wrapper']/table/tbody/tr/td[1]\")\n",
    "    for i in ranks:\n",
    "        if(i.text)!='':\n",
    "            rank.append(i.text)\n",
    "        else:\n",
    "            rank.append(\"--\")\n",
    "except NoSuchElementException:\n",
    "    rank.append(\"--\")\n",
    "    \n",
    "#Scraping State\n",
    "try:\n",
    "    states= driver.find_elements(By.XPATH, \"//div[@id='table_id_wrapper']/table/tbody/tr/td[2]\")\n",
    "    for i in states:\n",
    "        if(i.text)!='':\n",
    "            state.append(i.text)\n",
    "        else:\n",
    "            state.append(\"--\")\n",
    "except NoSuchElementException:\n",
    "    state.append(\"--\")\n",
    "    \n",
    "#Sraping GSDP(19-20)- at current prices\n",
    "try:\n",
    "    gsdp1s= driver.find_elements(By.XPATH, \"//div[@id='table_id_wrapper']/table/tbody/tr/td[3]\")\n",
    "    for i in gsdp1s:\n",
    "        if(i.text)!='':\n",
    "            gsdp1.append(i.text)\n",
    "        else:\n",
    "            gsdp1.append(\"--\")\n",
    "except NoSuchElementException:\n",
    "    gsdp1.append(\"--\")\n",
    "    \n",
    "#Sraping GSDP(18-19)- at current prices\n",
    "try:\n",
    "    gsdp2s= driver.find_elements(By.XPATH, \"//div[@id='table_id_wrapper']/table/tbody/tr/td[4]\")\n",
    "    for i in gsdp2s:\n",
    "        if(i.text)!='':\n",
    "            gsdp2.append(i.text)\n",
    "        else:\n",
    "            gsdp2.append(\"--\")\n",
    "except NoSuchElementException:\n",
    "    gsdp2.append(\"--\")\n",
    "    \n",
    "#Sraping Share\n",
    "try:\n",
    "    shares= driver.find_elements(By.XPATH, \"//div[@id='table_id_wrapper']/table/tbody/tr/td[5]\")\n",
    "    for i in shares:\n",
    "        if(i.text)!='':\n",
    "            share.append(i.text)\n",
    "        else:\n",
    "            share.append(\"--\")\n",
    "except NoSuchElementException:\n",
    "    share.append(\"--\")\n",
    "    \n",
    "#Sraping GDP\n",
    "try:\n",
    "    gdps= driver.find_elements(By.XPATH, \"//div[@id='table_id_wrapper']/table/tbody/tr/td[6]\")\n",
    "    for i in gdps:\n",
    "        if(i.text)!='':\n",
    "            gdp.append(i.text)\n",
    "        else:\n",
    "            gdp.append(\"--\")\n",
    "except NoSuchElementException:\n",
    "    gdp.append(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc643771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP(19-20)- at current prices</th>\n",
       "      <th>GSDP(18-19)- at current prices</th>\n",
       "      <th>Share</th>\n",
       "      <th>GDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>942,586</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>972,782</td>\n",
       "      <td>862,957</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>969,604</td>\n",
       "      <td>861,031</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>906,672</td>\n",
       "      <td>809,592</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>-</td>\n",
       "      <td>781,653</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>856,112</td>\n",
       "      <td>774,870</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>831,610</td>\n",
       "      <td>734,163</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>611,804</td>\n",
       "      <td>530,363</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>574,760</td>\n",
       "      <td>526,376</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>521,275</td>\n",
       "      <td>487,805</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>-</td>\n",
       "      <td>315,881</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>329,180</td>\n",
       "      <td>304,063</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>328,598</td>\n",
       "      <td>297,204</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>-</td>\n",
       "      <td>245,895</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>-</td>\n",
       "      <td>155,956</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>165,472</td>\n",
       "      <td>153,845</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>80,449</td>\n",
       "      <td>73,170</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>55,984</td>\n",
       "      <td>49,845</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>-</td>\n",
       "      <td>42,114</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>38,253</td>\n",
       "      <td>34,433</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>36,572</td>\n",
       "      <td>33,481</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>32,496</td>\n",
       "      <td>28,723</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>31,790</td>\n",
       "      <td>27,870</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>27,283</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>24,603</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>26,503</td>\n",
       "      <td>22,287</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP(19-20)- at current prices  \\\n",
       "0     1                Maharashtra                              -   \n",
       "1     2                 Tamil Nadu                      1,845,853   \n",
       "2     3              Uttar Pradesh                      1,687,818   \n",
       "3     4                    Gujarat                              -   \n",
       "4     5                  Karnataka                      1,631,977   \n",
       "5     6                West Bengal                      1,253,832   \n",
       "6     7                  Rajasthan                      1,020,989   \n",
       "7     8             Andhra Pradesh                        972,782   \n",
       "8     9                  Telangana                        969,604   \n",
       "9    10             Madhya Pradesh                        906,672   \n",
       "10   11                     Kerala                              -   \n",
       "11   12                      Delhi                        856,112   \n",
       "12   13                    Haryana                        831,610   \n",
       "13   14                      Bihar                        611,804   \n",
       "14   15                     Punjab                        574,760   \n",
       "15   16                     Odisha                        521,275   \n",
       "16   17                      Assam                              -   \n",
       "17   18               Chhattisgarh                        329,180   \n",
       "18   19                  Jharkhand                        328,598   \n",
       "19   20                Uttarakhand                              -   \n",
       "20   21            Jammu & Kashmir                              -   \n",
       "21   22           Himachal Pradesh                        165,472   \n",
       "22   23                        Goa                         80,449   \n",
       "23   24                    Tripura                         55,984   \n",
       "24   25                 Chandigarh                              -   \n",
       "25   26                 Puducherry                         38,253   \n",
       "26   27                  Meghalaya                         36,572   \n",
       "27   28                     Sikkim                         32,496   \n",
       "28   29                    Manipur                         31,790   \n",
       "29   30                   Nagaland                              -   \n",
       "30   31          Arunachal Pradesh                              -   \n",
       "31   32                    Mizoram                         26,503   \n",
       "32   33  Andaman & Nicobar Islands                              -   \n",
       "\n",
       "   GSDP(18-19)- at current prices   Share      GDP  \n",
       "0                       2,632,792  13.94%  399.921  \n",
       "1                       1,630,208   8.63%  247.629  \n",
       "2                       1,584,764   8.39%  240.726  \n",
       "3                       1,502,899   7.96%  228.290  \n",
       "4                       1,493,127   7.91%  226.806  \n",
       "5                       1,089,898   5.77%  165.556  \n",
       "6                         942,586   4.99%  143.179  \n",
       "7                         862,957   4.57%  131.083  \n",
       "8                         861,031   4.56%  130.791  \n",
       "9                         809,592   4.29%  122.977  \n",
       "10                        781,653   4.14%  118.733  \n",
       "11                        774,870   4.10%  117.703  \n",
       "12                        734,163   3.89%  111.519  \n",
       "13                        530,363   2.81%   80.562  \n",
       "14                        526,376   2.79%   79.957  \n",
       "15                        487,805   2.58%   74.098  \n",
       "16                        315,881   1.67%   47.982  \n",
       "17                        304,063   1.61%   46.187  \n",
       "18                        297,204   1.57%   45.145  \n",
       "19                        245,895   1.30%   37.351  \n",
       "20                        155,956   0.83%   23.690  \n",
       "21                        153,845   0.81%   23.369  \n",
       "22                         73,170   0.39%   11.115  \n",
       "23                         49,845   0.26%    7.571  \n",
       "24                         42,114   0.22%    6.397  \n",
       "25                         34,433   0.18%    5.230  \n",
       "26                         33,481   0.18%    5.086  \n",
       "27                         28,723   0.15%    4.363  \n",
       "28                         27,870   0.15%    4.233  \n",
       "29                         27,283   0.14%    4.144  \n",
       "30                         24,603   0.13%    3.737  \n",
       "31                         22,287   0.12%    3.385  \n",
       "32                              -       -        -  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data={'Rank':rank, 'State':state, 'GSDP(19-20)- at current prices':gsdp1, 'GSDP(18-19)- at current prices':gsdp2, \n",
    "      'Share':share, 'GDP':gdp}\n",
    "df = pd.DataFrame.from_dict(data, orient='index')\n",
    "df = df.transpose()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f2ba35",
   "metadata": {},
   "source": [
    "Scrape the details of trending repositories on Github.com. \n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used\n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6731f237",
   "metadata": {},
   "outputs": [],
   "source": [
    "github_url=driver.get(\"https://github.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3055450",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    nav_dropdown=driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/button')\n",
    "    nav_dropdown.click()\n",
    "    time.sleep(5)\n",
    "except NoSuchElementException:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3ae08b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    trending=driver.find_element(By.XPATH, '/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/div[3]/ul/li[2]/a')\n",
    "    trending.click()\n",
    "    time.sleep(4)\n",
    "except NoSuchElementException:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c10889e",
   "metadata": {},
   "outputs": [],
   "source": [
    "repository_title=[]\n",
    "description=[]\n",
    "count=[]\n",
    "language=[]\n",
    "\n",
    "#Scraping Repository Title\n",
    "try:\n",
    "    titles=driver.find_elements(By.XPATH, \"//h2[@class='h3 lh-condensed']\")\n",
    "    for i in titles:\n",
    "        if(i.text)!='':\n",
    "            repository_title.append(i.text)\n",
    "        else:\n",
    "            repository_title.append(\"--\")\n",
    "except NoSuchElementException:\n",
    "    repository_title.append(\"--\")\n",
    "    \n",
    "#Scraping Repository Description\n",
    "try:\n",
    "    descriptions=driver.find_elements(By.XPATH, \"//h2[@class='h3 lh-condensed']/following-sibling::p\")\n",
    "    for i in descriptions:\n",
    "        if(i.text)!='':\n",
    "            description.append(i.text)\n",
    "        else:\n",
    "            description.append(\"--\")\n",
    "except NoSuchElementException:\n",
    "    description.append(\"--\")\n",
    "    \n",
    "#Scraping Repository Contributors count\n",
    "try:\n",
    "    counts=driver.find_elements(By.XPATH, \"//article[@class='Box-row']/div[2]/a[1]\")\n",
    "    for i in counts:\n",
    "        if(i.text)!='':\n",
    "            count.append(i.text)\n",
    "        else:\n",
    "            count.append(\"--\")\n",
    "except NoSuchElementException:\n",
    "    count.append(\"--\")\n",
    "    \n",
    "#Scraping Repository Language\n",
    "try:\n",
    "    languages=driver.find_elements(By.XPATH, \"//article[@class='Box-row']/div[2]/span[1]/span[2]\")\n",
    "    for i in languages:\n",
    "        if(i.text)!='':\n",
    "            language.append(i.text)\n",
    "        else:\n",
    "            language.append(\"--\")\n",
    "except NoSuchElementException:\n",
    "    language.append(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c80ead4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository Title</th>\n",
       "      <th>Repository description</th>\n",
       "      <th>Contributors count</th>\n",
       "      <th>Language used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sadmann7 / skateshop</td>\n",
       "      <td>An open source e-commerce skateshop build with...</td>\n",
       "      <td>1,129</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sveltejs / svelte</td>\n",
       "      <td>Cybernetically enhanced web apps</td>\n",
       "      <td>69,829</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stability-AI / generative-models</td>\n",
       "      <td>Generative Models by Stability AI</td>\n",
       "      <td>1,542</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CASIA-IVA-Lab / FastSAM</td>\n",
       "      <td>Fast Segment Anything</td>\n",
       "      <td>1,109</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a16z-infra / ai-getting-started</td>\n",
       "      <td>A Javascript AI getting started stack for week...</td>\n",
       "      <td>1,927</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spacedriveapp / spacedrive</td>\n",
       "      <td>Spacedrive is an open source cross-platform fi...</td>\n",
       "      <td>19,448</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SkalskiP / top-cvpr-2023-papers</td>\n",
       "      <td>This repository is a curated collection of the...</td>\n",
       "      <td>352</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>zksync / credo</td>\n",
       "      <td>🔥 🔥 🔥 An intelligent and versatile general-pur...</td>\n",
       "      <td>659</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>chat2db / Chat2DB</td>\n",
       "      <td>Framework to easily create LLM powered bots ov...</td>\n",
       "      <td>922</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>embedchain / embedchain</td>\n",
       "      <td>Papers from the computer science community to ...</td>\n",
       "      <td>961</td>\n",
       "      <td>Shell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>papers-we-love / papers-we-love</td>\n",
       "      <td>A new bootable USB solution.</td>\n",
       "      <td>73,693</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ventoy / Ventoy</td>\n",
       "      <td>😎 Awesome lists about all kinds of interesting...</td>\n",
       "      <td>50,186</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sindresorhus / awesome</td>\n",
       "      <td>GPT 3.5/4 with a Chat Web UI. No API key requi...</td>\n",
       "      <td>259,209</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ramonvc / freegpt-webui</td>\n",
       "      <td>High-quality QR Code generator library in Java...</td>\n",
       "      <td>245</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>nayuki / QR-Code-generator</td>\n",
       "      <td>ChatGPT 中文调教指南。各种场景使用指南。学习怎么让它听你的话。</td>\n",
       "      <td>3,871</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>devfullcycle / imersao13</td>\n",
       "      <td>perfect programming language</td>\n",
       "      <td>152</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PlexPt / awesome-chatgpt-prompts-zh</td>\n",
       "      <td>PCSX2 - The Playstation 2 Emulator</td>\n",
       "      <td>39,963</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TodePond / DreamBerd</td>\n",
       "      <td>roop extension for StableDiffusion web-ui</td>\n",
       "      <td>4,027</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PCSX2 / pcsx2</td>\n",
       "      <td>The official gpt4free repository | various col...</td>\n",
       "      <td>8,885</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>s0md3v / sd-webui-roop</td>\n",
       "      <td>OpenCore bootloader</td>\n",
       "      <td>742</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>xtekky / gpt4free</td>\n",
       "      <td>🚀✨ Help beginners to contribute to open source...</td>\n",
       "      <td>41,062</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>acidanthera / OpenCorePkg</td>\n",
       "      <td>An API wrapper for Discord written in Python.</td>\n",
       "      <td>11,624</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>firstcontributions / first-contributions</td>\n",
       "      <td>[CVPR 2023 Best Paper] Planning-oriented Auton...</td>\n",
       "      <td>34,274</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Rapptz / discord.py</td>\n",
       "      <td>None</td>\n",
       "      <td>13,047</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>OpenDriveLab / UniAD</td>\n",
       "      <td>None</td>\n",
       "      <td>1,344</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Repository Title  \\\n",
       "0                       sadmann7 / skateshop   \n",
       "1                          sveltejs / svelte   \n",
       "2           Stability-AI / generative-models   \n",
       "3                    CASIA-IVA-Lab / FastSAM   \n",
       "4            a16z-infra / ai-getting-started   \n",
       "5                 spacedriveapp / spacedrive   \n",
       "6            SkalskiP / top-cvpr-2023-papers   \n",
       "7                             zksync / credo   \n",
       "8                          chat2db / Chat2DB   \n",
       "9                    embedchain / embedchain   \n",
       "10           papers-we-love / papers-we-love   \n",
       "11                           ventoy / Ventoy   \n",
       "12                    sindresorhus / awesome   \n",
       "13                   ramonvc / freegpt-webui   \n",
       "14                nayuki / QR-Code-generator   \n",
       "15                  devfullcycle / imersao13   \n",
       "16       PlexPt / awesome-chatgpt-prompts-zh   \n",
       "17                      TodePond / DreamBerd   \n",
       "18                             PCSX2 / pcsx2   \n",
       "19                    s0md3v / sd-webui-roop   \n",
       "20                         xtekky / gpt4free   \n",
       "21                 acidanthera / OpenCorePkg   \n",
       "22  firstcontributions / first-contributions   \n",
       "23                       Rapptz / discord.py   \n",
       "24                      OpenDriveLab / UniAD   \n",
       "\n",
       "                               Repository description Contributors count  \\\n",
       "0   An open source e-commerce skateshop build with...              1,129   \n",
       "1                    Cybernetically enhanced web apps             69,829   \n",
       "2                   Generative Models by Stability AI              1,542   \n",
       "3                               Fast Segment Anything              1,109   \n",
       "4   A Javascript AI getting started stack for week...              1,927   \n",
       "5   Spacedrive is an open source cross-platform fi...             19,448   \n",
       "6   This repository is a curated collection of the...                352   \n",
       "7   🔥 🔥 🔥 An intelligent and versatile general-pur...                659   \n",
       "8   Framework to easily create LLM powered bots ov...                922   \n",
       "9   Papers from the computer science community to ...                961   \n",
       "10                       A new bootable USB solution.             73,693   \n",
       "11  😎 Awesome lists about all kinds of interesting...             50,186   \n",
       "12  GPT 3.5/4 with a Chat Web UI. No API key requi...            259,209   \n",
       "13  High-quality QR Code generator library in Java...                245   \n",
       "14                ChatGPT 中文调教指南。各种场景使用指南。学习怎么让它听你的话。              3,871   \n",
       "15                       perfect programming language                152   \n",
       "16                 PCSX2 - The Playstation 2 Emulator             39,963   \n",
       "17          roop extension for StableDiffusion web-ui              4,027   \n",
       "18  The official gpt4free repository | various col...              8,885   \n",
       "19                                OpenCore bootloader                742   \n",
       "20  🚀✨ Help beginners to contribute to open source...             41,062   \n",
       "21      An API wrapper for Discord written in Python.             11,624   \n",
       "22  [CVPR 2023 Best Paper] Planning-oriented Auton...             34,274   \n",
       "23                                               None             13,047   \n",
       "24                                               None              1,344   \n",
       "\n",
       "   Language used  \n",
       "0     TypeScript  \n",
       "1     JavaScript  \n",
       "2         Python  \n",
       "3         Python  \n",
       "4     TypeScript  \n",
       "5           Rust  \n",
       "6         Python  \n",
       "7           Java  \n",
       "8         Python  \n",
       "9          Shell  \n",
       "10             C  \n",
       "11        Python  \n",
       "12          Java  \n",
       "13    TypeScript  \n",
       "14           C++  \n",
       "15        Python  \n",
       "16        Python  \n",
       "17             C  \n",
       "18        Python  \n",
       "19        Python  \n",
       "20          None  \n",
       "21          None  \n",
       "22          None  \n",
       "23          None  \n",
       "24          None  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data={'Repository Title':repository_title, 'Repository description':description, 'Contributors count':count, \n",
    "      'Language used':language}\n",
    "df = pd.DataFrame.from_dict(data, orient='index')\n",
    "df = df.transpose()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d9a50e",
   "metadata": {},
   "source": [
    "Scrape the details of top 100 songs on billiboard.com. \n",
    "Url = https:/www.billboard.com/\n",
    "You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e4e12861",
   "metadata": {},
   "outputs": [],
   "source": [
    "billboard_url=driver.get(\"https:/www.billboard.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3afc4ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    wait=WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.CLASS_NAME, 'ot-sdk-row')))\n",
    "    x=wait.find_element(By.XPATH, '//*[@id=\"onetrust-accept-btn-handler\"]')\n",
    "    x.click()\n",
    "except TimeoutException as e:\n",
    "    print(e) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f0baac42",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    topSong=driver.find_element(By.XPATH, '/html/body/div[3]/header/div/div[2]/div/div/div[2]/div[2]/div/div/nav/ul/li[1]/a')\n",
    "    topSong.click()\n",
    "    time.sleep(6)\n",
    "except NoSuchElementException:    \n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ab511ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    fullChart=driver.find_element(By.XPATH, '/html/body/div[3]/main/div[2]/div[1]/div[1]/div/div/div[3]/a')\n",
    "    fc=fullChart.get_attribute('href')\n",
    "    driver.get(fc)\n",
    "    time.sleep(8)\n",
    "except NoSuchElementException:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a6cfaca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "songName=[]\n",
    "artistName=[]\n",
    "lastweekRank=[]\n",
    "peakRank=[]\n",
    "weeksonBoard=[]\n",
    "\n",
    "#Scraping Song Name\n",
    "try:\n",
    "    songsName=driver.find_elements(By.XPATH, '//div[@class=\"o-chart-results-list-row-container\"]/ul/li[4]/ul/li[1]/h3')\n",
    "    for i in songsName:\n",
    "        name=i.text\n",
    "        if name!='':\n",
    "            songName.append(name)\n",
    "        else:\n",
    "            songName.append(\"--\")\n",
    "except NoSuchElementException:\n",
    "    songName.append(\"--\")\n",
    "        \n",
    "#Scraping Artist Name\n",
    "try:\n",
    "    artistsName=driver.find_elements(By.XPATH, '//div[@class=\"o-chart-results-list-row-container\"]/ul/li[4]/ul/li[1]/span')\n",
    "    for i in artistsName:\n",
    "        name=i.text\n",
    "        if name!='':\n",
    "            artistName.append(name)\n",
    "        else:\n",
    "            artistName.append(\"--\")\n",
    "except NoSuchElementException:\n",
    "    artistName.append(\"--\")\n",
    "    \n",
    "#Scraping Last Week Rank\n",
    "try:\n",
    "    lastweekRanks=driver.find_elements(By.XPATH, '//div[@class=\"o-chart-results-list-row-container\"]/ul/li[4]/ul/li[4]/span')\n",
    "    for i in lastweekRanks:\n",
    "        if(i.text)!='':\n",
    "            lastweekRank.append(i.text)\n",
    "        else:\n",
    "            lastweekRank.append(\"--\")\n",
    "except NoSuchElementException:\n",
    "    lastweekRank.append(\"--\")\n",
    "    \n",
    "#Scraping Peak Rank\n",
    "try:\n",
    "    peakRanks=driver.find_elements(By.XPATH, '//div[@class=\"o-chart-results-list-row-container\"]/ul/li[4]/ul/li[5]/span')\n",
    "    for i in peakRanks:\n",
    "        if(i.text)!='':\n",
    "            peakRank.append(i.text)\n",
    "        else:\n",
    "            peakRank.append(\"--\")\n",
    "except NoSuchElementException:\n",
    "    peakRank.append(\"--\")\n",
    "    \n",
    "#Scraping Weeks on Board\n",
    "try:\n",
    "    weeksonBoards=driver.find_elements(By.XPATH, '//div[@class=\"o-chart-results-list-row-container\"]/ul/li[4]/ul/li[6]/span')\n",
    "    for i in weeksonBoards:\n",
    "        if(i.text)!='':\n",
    "            weeksonBoard.append(i.text)\n",
    "        else:\n",
    "            weeksonBoard.append(\"--\")\n",
    "except NoSuchElementException:\n",
    "    weeksonBoard.append(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a06253d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song name</th>\n",
       "      <th>Artist name</th>\n",
       "      <th>Last week rank</th>\n",
       "      <th>Peak rank</th>\n",
       "      <th>Weeks on board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Last Night</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Flowers</td>\n",
       "      <td>Miley Cyrus</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fast Car</td>\n",
       "      <td>Luke Combs</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Calm Down</td>\n",
       "      <td>Rema &amp; Selena Gomez</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>All My Life</td>\n",
       "      <td>Lil Durk Featuring J. Cole</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Save Me</td>\n",
       "      <td>Jelly Roll With Lainey Wilson</td>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Yandel 150</td>\n",
       "      <td>Yandel &amp; Feid</td>\n",
       "      <td>-</td>\n",
       "      <td>71</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Beso</td>\n",
       "      <td>Rosalia &amp; Rauw Alejandro</td>\n",
       "      <td>94</td>\n",
       "      <td>52</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>I Wrote The Book</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "      <td>-</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Hummingbird</td>\n",
       "      <td>Metro Boomin &amp; James Blake</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Song name                    Artist name Last week rank Peak rank  \\\n",
       "0         Last Night                  Morgan Wallen              1         1   \n",
       "1            Flowers                    Miley Cyrus              2         1   \n",
       "2           Fast Car                     Luke Combs              4         3   \n",
       "3          Calm Down            Rema & Selena Gomez              3         3   \n",
       "4        All My Life     Lil Durk Featuring J. Cole              5         2   \n",
       "..               ...                            ...            ...       ...   \n",
       "95           Save Me  Jelly Roll With Lainey Wilson             86        86   \n",
       "96        Yandel 150                  Yandel & Feid              -        71   \n",
       "97              Beso       Rosalia & Rauw Alejandro             94        52   \n",
       "98  I Wrote The Book                  Morgan Wallen              -        18   \n",
       "99       Hummingbird     Metro Boomin & James Blake             90        90   \n",
       "\n",
       "   Weeks on board  \n",
       "0              20  \n",
       "1              22  \n",
       "2              12  \n",
       "3              41  \n",
       "4               5  \n",
       "..            ...  \n",
       "95              2  \n",
       "96             17  \n",
       "97             12  \n",
       "98             19  \n",
       "99              2  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data={'Song name':songName, 'Artist name':artistName, 'Last week rank':lastweekRank, 'Peak rank':peakRank, \n",
    "      'Weeks on board':weeksonBoard}\n",
    "df = pd.DataFrame.from_dict(data, orient='index')\n",
    "df = df.transpose()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d4a05e",
   "metadata": {},
   "source": [
    "Scrape the details of Highest sellingnovels.\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey\u0002compare\n",
    "You have to find the following details:\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "456ca32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sellingnovels_url=driver.get(\"https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1c8ac3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bookName=[]\n",
    "authorName=[]\n",
    "volumes=[]\n",
    "publisher=[]\n",
    "genre=[]\n",
    "\n",
    "#Scraping Book Name\n",
    "try:\n",
    "    bookNames=driver.find_elements(By.XPATH, \"//table[@class='in-article sortable']/tbody/tr/td[2]\")\n",
    "    for i in bookNames:\n",
    "        if(i.text)!='':\n",
    "            bookName.append(i.text)\n",
    "        else:\n",
    "            bookName.append(\"--\")\n",
    "except NoSuchElementException:\n",
    "    bookName.append(\"--\")\n",
    "\n",
    "#Scraping Author Name\n",
    "try:\n",
    "    authorNames=driver.find_elements(By.XPATH, \"//table[@class='in-article sortable']/tbody/tr/td[3]\")\n",
    "    for i in authorNames:\n",
    "        if(i.text)!='':\n",
    "            authorName.append(i.text)\n",
    "        else:\n",
    "            authorName.append(\"--\")\n",
    "except NoSuchElementException:\n",
    "    authorName.append(\"--\")\n",
    "    \n",
    "#Scraping volumes\n",
    "try:\n",
    "    volumess=driver.find_elements(By.XPATH, \"//table[@class='in-article sortable']/tbody/tr/td[4]\")\n",
    "    for i in volumess:\n",
    "        if(i.text)!='':\n",
    "            volumes.append(i.text)\n",
    "        else:\n",
    "            volumes.append(\"--\")\n",
    "except NoSuchElementException:\n",
    "    volumes.append(\"--\")\n",
    "    \n",
    "#Scraping publisher\n",
    "try:\n",
    "    publishers=driver.find_elements(By.XPATH, \"//table[@class='in-article sortable']/tbody/tr/td[5]\")\n",
    "    for i in publishers:\n",
    "        if(i.text)!='':\n",
    "            publisher.append(i.text)\n",
    "        else:\n",
    "            publisher.append(\"--\")\n",
    "except NoSuchElementException:\n",
    "    publisher.append(\"--\")\n",
    "    \n",
    "#Scraping genre\n",
    "try:\n",
    "    genres=driver.find_elements(By.XPATH, \"//table[@class='in-article sortable']/tbody/tr/td[6]\")\n",
    "    for i in genres:\n",
    "        if(i.text)!='':\n",
    "            genre.append(i.text)\n",
    "        else:\n",
    "            genre.append(\"--\")\n",
    "except NoSuchElementException:\n",
    "    genre.append(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "76d25f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author</th>\n",
       "      <th>Volumes</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book Name            Author  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "      Volumes        Publisher                        Genre  \n",
       "0   5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1   4,475,152       Bloomsbury           Children's Fiction  \n",
       "2   4,200,654       Bloomsbury           Children's Fiction  \n",
       "3   4,179,479       Bloomsbury           Children's Fiction  \n",
       "4   3,758,936     Random House              Romance & Sagas  \n",
       "..        ...              ...                          ...  \n",
       "95    807,311     Random House   General & Literary Fiction  \n",
       "96    794,201          Penguin        Food & Drink: General  \n",
       "97    792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98    791,507            Orion           Biography: General  \n",
       "99    791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data={'Book Name':bookName, 'Author':authorName, 'Volumes':volumes, 'Publisher':publisher, 'Genre':genre}\n",
    "df = pd.DataFrame.from_dict(data, orient='index')\n",
    "df = df.transpose()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4085d44f",
   "metadata": {},
   "source": [
    " Scrape the details most watched tv series of all time from imdb.com. \n",
    "Url = https://www.imdb.com/list/ls095964455/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c1491af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_url=driver.get(\"https://www.imdb.com/list/ls095964455/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4936c145",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[]\n",
    "yearSpan=[]\n",
    "genre=[]\n",
    "runTime=[]\n",
    "rating=[]\n",
    "votes=[]\n",
    "\n",
    "#Scraping Name\n",
    "try:\n",
    "    names=driver.find_elements(By.XPATH, \"//h3[@class='lister-item-header']/a\")\n",
    "    for i in names:\n",
    "        if(i.text)!='':\n",
    "            name.append(i.text)\n",
    "        else:\n",
    "            name.append(\"--\")\n",
    "except NoSuchElementException:\n",
    "    name.append(\"--\")\n",
    "    \n",
    "#Scraping Year Span\n",
    "try:\n",
    "    yearSpans=driver.find_elements(By.XPATH, \"//h3[@class='lister-item-header']/span[2]\")\n",
    "    for i in yearSpans:\n",
    "        if(i.text)!='':\n",
    "            yearSpan.append(i.text)\n",
    "        else:\n",
    "            yearSpan.append(\"--\")\n",
    "except NoSuchElementException:\n",
    "    yearSpan.append(\"--\")\n",
    "\n",
    "#Scraping Genre\n",
    "try:\n",
    "    genres=driver.find_elements(By.XPATH, \"//div[@class='lister-item-content']/p/span[5]\")\n",
    "    for i in genres:\n",
    "        if(i.text)!='':\n",
    "            genre.append(i.text)\n",
    "        else:\n",
    "            genre.append(\"--\")\n",
    "except NoSuchElementException:\n",
    "    genre.append(\"--\")\n",
    "    \n",
    "#Scraping Run Time\n",
    "try:\n",
    "    runTimes=driver.find_elements(By.XPATH, \"//div[@class='lister-item-content']/p/span[3]\")\n",
    "    for i in runTimes:\n",
    "        if(i.text)!='':\n",
    "            runTime.append(i.text)\n",
    "        else:\n",
    "            runTime.append(\"--\")\n",
    "except NoSuchElementException:\n",
    "    runTime.append(\"--\")\n",
    "    \n",
    "#Scraping Ratings\n",
    "try:\n",
    "    ratings=driver.find_elements(By.XPATH, \"//div[@class='lister-item-content']/div[1]/div[1]/span[2]\")\n",
    "    for i in ratings:\n",
    "        if(i.text)!='':\n",
    "            rating.append(i.text)\n",
    "        else:\n",
    "            rating.append(\"--\")\n",
    "except NoSuchElementException:\n",
    "    rating.append(\"--\")\n",
    "    \n",
    "#Scraping Votes\n",
    "try:\n",
    "    votess=driver.find_elements(By.XPATH, \"//div[@class='lister-item-content']/p[4]/span[2]\")\n",
    "    for i in votess:\n",
    "        if(i.text)!='':\n",
    "            votes.append(i.text)\n",
    "        else:\n",
    "            votes.append(\"--\")\n",
    "except NoSuchElementException:\n",
    "    votes.append(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "afb2ce9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run Time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,172,794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016–2024)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,250,758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,032,045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>303,457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>262,642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>51,936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>63,975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>208,475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>43,380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>259,999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year Span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things  (2016–2024)    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds     (2005– )     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run Time Ratings      Votes  \n",
       "0    57 min     9.2  2,172,794  \n",
       "1    51 min     8.7  1,250,758  \n",
       "2    44 min     8.1  1,032,045  \n",
       "3    60 min     7.5    303,457  \n",
       "4    43 min     7.6    262,642  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.4     51,936  \n",
       "96   50 min     7.8     63,975  \n",
       "97   42 min     8.1    208,475  \n",
       "98   45 min     7.1     43,380  \n",
       "99  572 min     8.6    259,999  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data={'Name':name, 'Year Span':yearSpan, 'Genre':genre, 'Run Time':runTime, 'Ratings':rating, 'Votes':votes}\n",
    "df = pd.DataFrame.from_dict(data, orient='index')\n",
    "df = df.transpose()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4c8044",
   "metadata": {},
   "source": [
    "Details of Datasetsfrom UCI machine learning repositories. \n",
    "Url = https://archive.ics.uci.edu/\n",
    "You have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute\n",
    "G) Year\n",
    "Note: - from the home page you have to go to the ShowAllDataset page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9c41d08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "uci_url=driver.get(\"https://archive.ics.uci.edu/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "95e6fe9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetching view all dataset button from the webpage\n",
    "try:    \n",
    "    viewall_dataset = driver.find_element(By.XPATH, \"/html/body/div/div[1]/div[1]/main/div/div[1]/div/div/div/a[1]\")\n",
    "    page_url = viewall_dataset.get_attribute(\"href\")\n",
    "    driver.get(page_url)\n",
    "    time.sleep(3)\n",
    "except NoSuchElementException:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "add4a5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#accept btn\n",
    "try:\n",
    "    wait=WebDriverWait(driver, 10).until(EC.visibility_of_element_located((By.XPATH, \"/html/body/div/div[1]/div[1]/div\")))\n",
    "    x=wait.find_element(By.XPATH, \"/html/body/div/div[1]/div[1]/div/div[2]/button\")\n",
    "    x.click()\n",
    "except TimeoutException as e:\n",
    "   print(e)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "612a827f",
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[]\n",
    "dataset_type=[]\n",
    "task=[]\n",
    "attribute_type=[]\n",
    "noofInstances=[]\n",
    "noofAttribute=[]\n",
    "year=[]\n",
    "\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        expand=driver.find_element(By.XPATH, '/html/body/div/div[1]/div[1]/main/div/div[2]/div[1]/div/label[2]')\n",
    "        expand.click()\n",
    "        time.sleep(2)\n",
    "    except NoSuchElementException as e:\n",
    "        print(\"Expand Btn not available\", e)\n",
    "    \n",
    "    #Scraping Dataset Name\n",
    "    try:\n",
    "        names=driver.find_elements(By.XPATH, '//h2')\n",
    "        for i in names:\n",
    "            if(i.text)!='':\n",
    "                name.append(i.text)\n",
    "            else:\n",
    "                name.append('--')\n",
    "    except NoSuchElementException:\n",
    "        name.append(\"--\")\n",
    "\n",
    "    #Scraping Dataset Type\n",
    "    try:\n",
    "        dataset_types=driver.find_elements(By.XPATH, \"//div[@class='my-2 hidden gap-4 md:grid grid-cols-12']/div[2]/span\")  \n",
    "        for i in dataset_types:\n",
    "            if(i.text)!='':\n",
    "                dataset_type.append(i.text)\n",
    "            else:\n",
    "                dataset_type.append('--')\n",
    "    except NoSuchElementException:\n",
    "        dataset_type.append(\"--\")\n",
    "\n",
    "    #Scraping Task\n",
    "    try:\n",
    "        tasks=driver.find_elements(By.XPATH, \"//div[@class='my-2 hidden gap-4 md:grid grid-cols-12']/div[1]/span\")  \n",
    "        for i in tasks:\n",
    "            if(i.text)!='':\n",
    "                task.append(i.text)\n",
    "            else:\n",
    "                task.append('--')\n",
    "    except NoSuchElementException:\n",
    "        task.append(\"--\")\n",
    "\n",
    "    #Scraping Attribute Type\n",
    "    try:\n",
    "        attribute_types=driver.find_elements(By.XPATH, \"//tbody[@class='border']/tr/td[2]\")  \n",
    "        for i in attribute_types:\n",
    "            if(i.text)!='':\n",
    "                attribute_type.append(i.text)\n",
    "            else:\n",
    "                attribute_type.append('--')\n",
    "    except NoSuchElementException:\n",
    "        attribute_type.append(\"--\")\n",
    "\n",
    "    #Scraping No of Instances\n",
    "    try:\n",
    "        noofInstancess=driver.find_elements(By.XPATH, \"//div[@class='my-2 hidden gap-4 md:grid grid-cols-12']/div[3]/span\")  \n",
    "        for i in noofInstancess:\n",
    "            if(i.text)!='':\n",
    "                noofInstances.append(i.text.replace(' Instances', ''))\n",
    "            else:\n",
    "                noofInstances.append('--')\n",
    "    except NoSuchElementException:\n",
    "        noofInstances.append(\"--\")\n",
    "\n",
    "    #Scraping No of Attributes\n",
    "    try:\n",
    "        noofAttributes=driver.find_elements(By.XPATH, \"//div[@class='my-2 hidden gap-4 md:grid grid-cols-12']/div[4]/span\")  \n",
    "        for i in noofAttributes:\n",
    "            if(i.text)!='':\n",
    "                noofAttribute.append(i.text.replace(' Attributes', ''))\n",
    "            else:\n",
    "                noofAttribute.append('--')\n",
    "    except NoSuchElementException:\n",
    "        noofAttribute.append(\"--\")\n",
    "\n",
    "    #Scraping Year\n",
    "    try:\n",
    "        yrs=driver.find_elements(By.XPATH, \"//tbody[@class='border']/tr/td[3]\")  \n",
    "        for i in yrs:\n",
    "            if(i.text)!='':\n",
    "                year.append(i.text.split('/')[-1])\n",
    "            else:\n",
    "                year.append('--')\n",
    "    except NoSuchElementException:\n",
    "        year.append(\"--\") \n",
    "        \n",
    "    try:\n",
    "        next_page = driver.find_element(By.XPATH, \"/html/body/div/div[1]/div[1]/main/div/div[2]/div[3]/div/button[2]\")   \n",
    "        if next_page.is_enabled():\n",
    "            next_page.click()\n",
    "        else:\n",
    "            break\n",
    "    except ElementClickInterceptedException as e:\n",
    "        break\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "356f3d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset name</th>\n",
       "      <th>Data type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute type</th>\n",
       "      <th>No of instances</th>\n",
       "      <th>No of attribute</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>303</td>\n",
       "      <td>13</td>\n",
       "      <td>1988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dry Bean Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>13.61K</td>\n",
       "      <td>17</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48.84K</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>--</td>\n",
       "      <td>20</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>Undocumented</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>None</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>EBL Domain Theories</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>None</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>Moral Reasoner</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>None</td>\n",
       "      <td>202</td>\n",
       "      <td>--</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>DGP2 - The Second Data Generation Program</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>None</td>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>Single elder home monitoring: Gas and position</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>None</td>\n",
       "      <td>444.63K</td>\n",
       "      <td>16</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>623 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Dataset name     Data type  \\\n",
       "0                                              Iris  Multivariate   \n",
       "1                                     Heart Disease  Multivariate   \n",
       "2                                  Dry Bean Dataset  Multivariate   \n",
       "3                                             Adult  Multivariate   \n",
       "4                                          Diabetes            --   \n",
       "..                                              ...           ...   \n",
       "618                                    Undocumented            --   \n",
       "619                             EBL Domain Theories            --   \n",
       "620                                  Moral Reasoner            --   \n",
       "621       DGP2 - The Second Data Generation Program            --   \n",
       "622  Single elder home monitoring: Gas and position       Tabular   \n",
       "\n",
       "               Task              Attribute type No of instances  \\\n",
       "0    Classification                        Real             150   \n",
       "1    Classification  Categorical, Integer, Real             303   \n",
       "2    Classification               Integer, Real          13.61K   \n",
       "3    Classification        Categorical, Integer          48.84K   \n",
       "4                --        Categorical, Integer              --   \n",
       "..              ...                         ...             ...   \n",
       "618              --                        None              --   \n",
       "619              --                        None              --   \n",
       "620              --                        None             202   \n",
       "621              --                        None              --   \n",
       "622  Classification                        None         444.63K   \n",
       "\n",
       "    No of attribute  Year  \n",
       "0                 4  1988  \n",
       "1                13  1988  \n",
       "2                17  2020  \n",
       "3                14  1996  \n",
       "4                20     A  \n",
       "..              ...   ...  \n",
       "618              --  None  \n",
       "619              --  None  \n",
       "620              --  None  \n",
       "621              --  None  \n",
       "622              16  None  \n",
       "\n",
       "[623 rows x 7 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data={'Dataset name':name, 'Data type':dataset_type, 'Task':task, 'Attribute type':attribute_type, \n",
    "      'No of instances':noofInstances, 'No of attribute':noofAttribute, 'Year':year}\n",
    "df = pd.DataFrame.from_dict(data, orient='index')\n",
    "df = df.transpose()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9c98d6",
   "metadata": {},
   "source": [
    "Scrape the details of Data science recruiters Url = https://www.naukri.com/hr-recruiters-consultants\n",
    "You have to find the following details: \n",
    "A) Name\n",
    "B) Designation\n",
    "C)Company \n",
    "D)Skills they hire for \n",
    "E) Location\n",
    "Note: - From naukri.com homepage click on the recruiters option and the on the search pane type Data science and \n",
    "click on search. All this should be done through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d96c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "naukri_url=driver.get(\"https://www.naukri.com/hr-recruiters-consultants\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da9e00d",
   "metadata": {},
   "source": [
    "Raised a ticket on access to the above link and got a reply saying I can skip for now. Ticket No - 17213\n",
    "https://www.flipnwork.com/index.php/tickets/view/17213"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
